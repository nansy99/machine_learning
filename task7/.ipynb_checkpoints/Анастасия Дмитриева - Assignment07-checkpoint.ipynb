{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 1. Смещение константного алгоритма (2 балла)\n",
    "Пусть $x \\in R^d$, и значение каждого признака на объекте $x$ независимо генерируется из равномерного распределения $x_i\\in U[0,1],i=1,2\\dots,d$. Будем считать, что объекты в выборке независимы, а $\\mathbb{E}[y|x]=x^Tx.$ Найдите смещение константного алгоритма, полученного минимизацией среднеквадратичной ошибки на обучающей выборке. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 2. Разложение ошибки (2 балла)\n",
    "Истинная зависимость имеет вид $y_i = 3x^2_i+ u_i$, где $y_i$ - прогнозируемая переменная, $x_i$-признак и $u_i$ - случайная составляющая. Величины $x_i$ независимы и равновероятно принимаю значения $0, 1, 2$. Величины $u_i$ независимы и равновероятно принимают значения $−1$ и $1$.\n",
    "Исследователь Анатолий оценивает модель линейной регрессии $y_i = wx_i$, минимизируя среднеквадратичную ошибку.\n",
    "Разложите ожидание квадрата ошибки прогноза на шум, смещение и разброс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 3. Взвешенное голосование (2 балла)\n",
    "Рассмотрим задачу бинарной классификации, пусть у нас есть три алгоритма $b_1(x), b_2(x)$ и $b_3(x)$, каждый из которых ошибается с вероятностью $p$. Мы строим композицию взвешенным голосованием: алгоритмам присвоены значимости $w_1, w_2$ и $w_3$, и для вынесения вердикта суммируются значимости алгоритмов, проголосовавших за каждый из классов:\n",
    "$$\n",
    "a_0=\\sum_{i=1}^3w_i[b_i(x)=0], $$\n",
    "$$\n",
    "a_1=\\sum_{i=1}^3w_i[b_i(x)=1]. \\\\\n",
    "$$\n",
    "Объект $x$ относится к классу, для которого сумма оказалась максимальной. Например, если первые два алгоритма голосуют за класс $0$, а третий за класс $1$, то выбирается класс $0$, если $w_1+w_2>w_3$, и класс $1$ в противном случае. Какова вероятность ошибки такой композиции этих трех алгоритмов, если:\n",
    "\n",
    "* $w_1=0.3, w_2=0.4, w_3=0.3$;\n",
    "* $w_1=0.2, w_2=0.5, w_3=0.2$?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 4. Разложение ошибки с помощью бутстрапа "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании вам предстоит воспользоваться возможностями bootstraping для оценки смещения и разброса алгоритмов машинного обучения. Делать мы это будем на данных boston:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((506, 13), (506,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = load_boston()\n",
    "X = boston[\"data\"]\n",
    "y = boston[\"target\"]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Алгоритм оценки смещения и разброса алгоритма $a$\n",
    "\n",
    "1. Сгенерировать $s$ выборок $X_j$ методом бутстрапа.\n",
    "\n",
    "2. На каждой выборке $X_j$ обучить алгоритм $a_j$.\n",
    "\n",
    "3. Для каждой выборки $X_j$ определить множество объектов $T_j$, не вошедших в нее (out-of-bag). Вычислить предсказания алгоритма $a_j$ на объектах $T_j$.\n",
    "\n",
    "Поскольку у нас есть только один ответ для каждого объекта, мы будем считать шум равным 0, а $\\mathbb{E}[y|x]$ равным имеющемуся правильному ответу для объекта $x$.\n",
    "\n",
    "#### Итоговые оценки:\n",
    "\n",
    "* #### Смещение: \n",
    "для одного объекта - квадрат разности среднего предсказания и правильного ответа. Среднее предсказание берется только по тем алгоритмам $a_j$, для которых этот объект входил в out-of-bag выборку $T_j$. Для получения общего смещения выполнить усреденение смещений по объектам.\n",
    "* #### Разброс: \n",
    "для одного объекта - выборочная дисперсия предсказаний алгоритмов $a_j$, для которых этот объект входил в out-of-bag выборку $T_j$. Для получения общего разброса выполнить усреденение разбросов по объектам.\n",
    "* #### Ошибка $L$:\n",
    "усреднить квадраты разностей предсказания и правильного ответа по всем выполненным предсказаниям для всех объектов.\n",
    "\n",
    "В результате должно получиться, что ошибка приблизительно равна сумме смещения и разброса!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* реализуйте описанный алгоритм. Обратите внимание, что если объект не вошел ни в одну из out-of-bag выборок, учитывать его в вычислении итоговых величин не нужно. (3 балла) \n",
    "\n",
    "* Оцените смещение, разброс и ошибку для трех алгоритмов с гиперпараметрами по умолчанию: линейная регрессия, решающее дерево, случайный лес.\n",
    "\n",
    "* Проанализируйте полученный результат. Согласуются ли полученные результаты с теми, что мы обсуждали на занятиях? (1 балл)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#реализуйте описанный алгоритм. \n",
    "#Обратите внимание, что если объект не вошел ни в одну из out-of-bag выборок, \n",
    "#учитывать его в вычислении итоговых величин не нужно\n",
    "\n",
    "def compute(algorithm, X, y, s=1000):\n",
    "    N = X.shape[0]\n",
    "    y_pred = np.full(fill_value=np.nan, shape=(s, N))\n",
    "    sum_sample = np.zeros(shape=(1, N))[0]\n",
    "    counter = np.zeros(N)\n",
    "    \n",
    "    for i in range(s):\n",
    "        X_i = np.random.choice(N, N) # рандомная подвыборка\n",
    "        T_i = np.setdiff1d(np.arange(N), X_i) # out-of-bag\n",
    "        if T_i.shape[0] == 0:\n",
    "            continue\n",
    "        X_sample, y_sample = X[X_i], y[X_i] \n",
    "        pred = algorithm.fit(X_sample, y_sample).predict(X[T_i]) #обучаем алгоритм на подвыборке\n",
    "                                                                #ищем предсказание на out-of-bag\n",
    "        y_pred[i].flat[T_i] = pred #храним предсказания\n",
    "        sum_sample[T_i] += pred\n",
    "        counter[T_i] += 1  #храним индексы тех,кто в out- of- bag\n",
    "    \n",
    "    #берем только по тем алгоритмам, для которых этот объект входил в out-of-bag выборку  \n",
    "    nonzero_ind = (counter > 1) #берем только те, кто входит в out -of -bag\n",
    "    sum_sample = sum_sample.reshape(1, -1)[0][nonzero_ind]\n",
    "    y = y[nonzero_ind]\n",
    "    counter = counter[nonzero_ind]\n",
    "    y_pred = y_pred[:, nonzero_ind]\n",
    "    \n",
    "    \n",
    " \n",
    "    bias = np.mean((sum_sample / counter - y) ** 2) # усредненный квадрат разности среднего \n",
    "                                                     #предсказания и правильного ответа \n",
    "    \n",
    "    tmp = ((y_pred - sum_sample/ counter) ** 2)\n",
    "    variance = np.mean(np.nansum(tmp, axis=0) / (np.sum(~np.isnan(tmp), axis=0) - 1)) #усредненная дисперсия предсказаний\n",
    "    \n",
    "    error = np.nanmean((y_pred - y.T) ** 2) #усредненый квадрат разности предсказания и правильного ответа \n",
    "    \n",
    "    return bias, variance, error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bias |  variance | error \n",
      "LinearRegression (23.729711956271203, 0.9385683903302623, 24.601168353748506)\n",
      "DecisionTreeRegressor (10.431664996392175, 12.864984085538195, 23.354579026776268)\n",
      "RandomForestRegressor (10.5845731997286, 3.3497450617595743, 14.075530336455639)\n"
     ]
    }
   ],
   "source": [
    "#Оцените смещение, разброс и ошибку для трех алгоритмов с гиперпараметрами по умолчанию: \n",
    "#линейная регрессия, решающее дерево, случайный лес.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "print(\" bias |  variance | error \")\n",
    "print(\"LinearRegression\", compute(LinearRegression(), X, y))\n",
    "print(\"DecisionTreeRegressor\", compute(DecisionTreeRegressor(), X, y))\n",
    "print(\"RandomForestRegressor\", compute(RandomForestRegressor(), X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Проанализируйте полученный результат. \n",
    "#Согласуются ли полученные результаты с теми, что мы обсуждали на занятиях?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Линейная регрессия имеет достаточно большое смещение, так как пытаемся приблизить нелинейную функцию. Так как данные несильно зашумлены, то разбром небольшой. \\\n",
    "2) Рещающее дерево имеет меньшее смещение, так как используя дерево возможно приблизить любую функцию.Так как решающие деревья — это алгоритмы, неустойчивые к изменениям обучающей выборки,то разброс достаточно большой. \\\n",
    "3) Случайный лес имеет такое же смещение, как и решающее дерево, разброс же уменьшается за счет использования бэггинга. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
